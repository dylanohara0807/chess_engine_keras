# Validation Loss versus Training Loss

It can be seen very clearly in the pathetic_cengine_model (pcm) that despite a very low training loss, 
the validation loss is much higher, which is to be expected somewhat, however it is higher than we'd like.
The lowlevel_cengine_model (llcm) produces the same training loss, however, the validation loss is much lower.
What this might tell us is that the pcm is overfitting the data, leading to bad validtion splits. The reason
for this might be because of the dataset differences, where the pcm is trained on 100,000 examples, llcm is
trained on 1,000,000 examples, allowing for a better general fit.

# Validation Loss in Large Datasets

Although the validation loss seems to perform better using a larger dataset, when using a very large set
(10,000,000) the overall loss will be higher, which is to be expected, however, the validation seems to be much
higher than the other examples. When looking, at training_loss/validation_loss, for the llcm, validation is about
11x times worse than the training data, whereas the exp_cengine_model (ecm) the ratio is only about 3x. That being
said, the increasing validation loss is undesireable.

# Increasing Validation Loss

It's important to recognize that chess is a massively complex game, so given a neural network that can recognize
certain patterns, it still may not translate well to similar patterns with small differences, which may be the
reason for the drastic increase for validation loss, even though the training/validation datasets should not be
drastically different in terms of positional composition. One thing that would improve the performance of the model
would be to introduce minimax/alpha-beta pruning in order to dive deeper into a given position, and perhaps discover
a more recognizable position, allowing for better performance. This would have to be implemented seperately of the
model's training however, as the neural network most simply takes a single board representation, not a set of them.
So it would only increase performance during actual depth analysis, not during training/validation.

# Increasing Parameters

An increased number of inputs has only improved the model's performance, however, it may simply be that the network
can extrapolate its own meanigful values from non-important inputs. This works, but may not be ideal when we think 
about generalizing the machine. One of the things that would allow the model to be more computationally independent
would be to give pieces more value based on where they are. For example, the queen may be a higher valued piece when
it approaches the middle of the board. Another large simplification would allow the model to treat a the general 
vicinity of the king as an input itself, generally kings that have been castled are safe. I plan on hopefully
implmenting the first suggestion, based on general chess principles, placing more information on a piece's value should
help the machine develop nuanced views.

# Limitations

There is simply not enough memory or computing power to create an exceptionally large neural network. For example,
around 16,000 nodes in the first layer, allowing one each for the combination of king positions (relative to each quadrant)
results in a too large model, at least for a Mac M1. Perhaps a specialized model could be created that learned only
on closed chess positions, or endgame positions, or positions with only minor pieces and pawns. Either way, it is
certainly interesting to see how effective a chess engine might be given different types of inputs. One thing I've
noticed is that the engine does seem to recognize when a position will result in material imbalance, even before the
actual imbalance. Though, obviously the engine is not breaking any records lol.